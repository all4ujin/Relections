Relections
==========

Stat 157 Weekly Reflections

Weekly Reflection of Week 5 - 09/30/2013

Tuesday, I found out that there are three integrators (presenters) in our group including myself. We will be splitting into new vertical teams of four. Among our horizontal integrator group, we discusssed some things that would be important for us.

**What tools do we need?**
	
	Powerpoint, Word, Prezdi, Youtube, iPython notebook, Keynote, LaTex, Google Docs
	But for this assignment, we would specifically use iPython notebook or an HTML5-based presentation

**What skills should we develope?**
	
	Voice projection, public speaking, general speaking skills, practice with interacting with audience/questions
	
**What are our responsibilities?**
	
	Making presentations, practicing presentations, internalizing materials, communicating with the team, getting best practices, integrating visualization into presentations

**What are our outputs?**
	
	Presentation, in both physical and digital forms

**How do we communicate with other groups?**

	Github, IRC, email, Google Docs, Skype, Facebook, texts
	
**How do we share techniques as a group?**

	Presentation on Google Drive, email
	Our group thought it would be best to meet up in person after/before class

**What is our stack/workflow?**

	Get process/results from team, practice/present to them, get feedback on important points, bounce off other presenters


Thusrday
======

Some Stochastic Models for Seismicity
* Poisson
* Gamma renewal proccesses
* Weibull, lognormal, normal, double exponential
* ETAS
* BRownian passage time
    
USGS 1999 Forecast
* P(M ≥ 6.7 event by 2030) = 0.7 ± 0.1
* Two big stages
    
   
* Determine regional constraints on aggregate fault motions from geodetic measurements.
* Map faults and fault segments; identify segments with slip rate >= 1 mm/y. Estimate the slip on each fault segment principally from paeloseismic data, occasionally augmented by geodetic and other data. Determine (by expert opinion) for each segment a 'slip factor,' the extent to which long-term slip on the segment is accommodated aseismically. Represent uncertainty in fault segment legnths, widths, and slip factors as independent Gaussian random variables with mean 0. Draw a set of fault segment dimensions and slip factors at random from that probability distribution.
* Identify (by expert opinion) ways in which segments of each fault can rupture separately and together. Each combination of segments in a 'seismic source.'
* Determine (by expert opinion) the extent to which long-term fault slip is accommodated by rupture of each combination of segments for each fault. 
* Choose at random (with probabilities of 0.2, 0.2, and 0.6) 1 of 4 generic relationships between fault are and moment elease to characerize magnitudes of events that each combination of fault segments supports. Represent the uncertainty in the generic relationship as Gaussian with zero mean and standard deviation 0.12, independent of fault areas.
* Using the chosen relationship and the assumed probability distribution for its parameters, determine a mean event magnitude for each seismic source by Monte Carlo.
* Combine seismic sources each fault 'to honor their relative likelihood as specified by the expert groups' adjust relative frequencies of events on each source so that every fault segment matches its estimated geologic slip rate. Discard combinations of sources that violate a regional slip constraint. Treat the 2,000 models as equally likely for estimating magnitudes, rates, and uncertainties.
* Estimate the background rate of seismicity: Use an (unspecified) Bayesian procedure to categorize historical events from three catalogs either as associated or not associated with the seven fault systems. Fit generic Gutenberg-Richter magnitude-frequency relation N(M) = 10^{a - b M} to the events deemed not to be associated with the seven fault systems. Model background seismicity as a marked Poisson process. Extrapolate the Poisson model to M≥ 6.7, which gives a probabibility of at least one event. 

**Stage 1** 
* Generaet 2,000 models; estimaet long-term sismicity rates as a function of magnitude for each sismic source/
**Stage 2** 
1. Fit 3 types of stochastic models for earthquakes recurrence - Poisson, Brownian passage time (Ellsworth etal., 1998), and 'time-predictable' - to the long-term seismicity rates estimated in stage 1.
2. Combine stochastic models to estimate the probability of a large earthquake.


* Poisson and Brownian passage time models used to estimate the probability an earthquake will rupture each fault segment. 

* Some parameters fitted to data;some were set more arbitrarily. Aperiodicity (standard deviation of recurrence time, divided by expected recurrence time) set to three different values, 0.3, 0.5, and 0.7. Method needs estimated date of last rupture of each segment.

* Model redistrubition of stress by large earthquakes; predictions made w/ & w/p adjustments for stress redistrubitions.

* Predctions for segments combined into predictions for each fault using expert opinion about the relative likelihoods of different ruptrue sources.

**So what does it mean?**
* I have no idea. It's just a number.
* None of the standard interpretations of probability applies.
* Method has aspects of Fisher's fiducial inference, frequency theory, probability models, subjective probability.
* Frequencies equated to probabilites; outcomes assumed to be equally likely; subjective probabilites used in ways that vilate Bayes' Rule.
* Calibrated using data that are not commensuarale - global, or extrapolated across magnitude ranges using 'empirical' scaling laws.
* Models upon modles; ad hoc ad nauseum.
* Inconsistent and virtually opaque.
* Better to spend resources on prepardeness, education, outreach.


**Null Hypotheses for Testing Predictions**
* Poisson seismicity, historical rates; predictions fixed
* Poisson seismicity after 'declustering,' historical rates; pedcitions fixed
* Locations from catalogs, times uniform; predictions fixed
* Locations from catalobs, times permuted; predictions fixed
    
**Need reasonale null hypothesis and a test statistic**
* Potential test statistic; parimutuel payoff
* Comes from horse racing
* Winners of a bet share the total amount wagered on that bet, in proportion to the amount they wagered
* If the total wagered for and against an outcome was $W, and $Wf was wagered that it would occur, everyone who bet in favor of the outcome gets $Wf/W back for every $ 1 he or she bet
